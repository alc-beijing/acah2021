---
title: "Declarative Benchmarking of Cassandra and Its Data Models"
date: "2019-09-11T14:15:00"
track: "cassandra"
presenters: "Monal Daxini"
---

You have made changes to Cassandra code base. How do you benchmark these changes for scalability and correctness, including different data models (schema), easily? You have created a Cassandra schema for your service. How do you ensure this is scalable?  How can you emulate application specific CQL queries, with specified distribution, to validate scale of your schema and associated data scalability without having to code your whole application? I am the author of the NDBench CQL Plugin tool, which was built at Netflix to address these needs and more, Declaratively. One of the Cassandra committers has called this tool 'Game Changing'. This plugin is currently (June 2019) being prepped to be open sourced ahead of this talk. This talk presents:  1. An example of how we used declarative benchmarking to achieve 1 Million requests per second for a user specified data model and query distribution backing a critical service at Netflix. 2. For users: n    a. How to certify scalability of new or existing data models on new version of Cassandra, for confident upgrades?n    b. How to certify scalability of new complex data models? 3. For committers: n    a. Define various profiles to emulate real world use cases to build confidence in changes and certifying new releases. n    b. Compare scalability of the same data model across different Cassandra version. 4. The philosophy of the tool, itâ€™s internal architecture, and future enhancements.